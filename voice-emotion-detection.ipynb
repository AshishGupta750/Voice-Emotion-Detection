import os
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import librosa
import librosa.display
import warnings
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix
import joblib
import ipywidgets as widgets
from IPython.display import display, Audio

warnings.filterwarnings('ignore')

# 1. Load Dataset

def load_data(input_dir):
    data = []
    labels = []
    for root, _, files in os.walk(input_dir):
        for file in files:
            if file.endswith('.wav'):
                path = os.path.join(root, file)
                label = file.split('-')[-1].replace('.wav', '')
                data.append(path)
                labels.append(label)
    return pd.DataFrame({'speech': data, 'label': labels})

# Replace with your dataset path
input_dir = 'data'
df = load_data(input_dir)
print(f"Loaded {len(df)} samples")
df.head()

# 2. EDA: Label Distribution
sns.countplot(x='label', data=df)
plt.title('Emotion Counts')
plt.show()

# 3. Visualization Helpers
def plot_waveform(path, title='Waveform'):
    y, sr = librosa.load(path, sr=None)
    plt.figure()
    librosa.display.waveshow(y, sr=sr)
    plt.title(title)
    plt.show()


def plot_spectrogram(path, title='Spectrogram'):
    y, sr = librosa.load(path, sr=None)
    D = librosa.stft(y)
    plt.figure()
    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D)), sr=sr, 
                             y_axis='log', x_axis='time')
    plt.title(title)
    plt.colorbar(format='%+2.0f dB')
    plt.show()

# Example plots
sample_path = df['speech'][df['label']=='happy'].iloc[0]
plot_waveform(sample_path, 'Waveform - Happy')
plot_spectrogram(sample_path, 'Spectrogram - Happy')

# 4. Feature Extraction
import librosa.feature as lf

def extract_features(path):
    y, sr = librosa.load(path, sr=None)
    # MFCC
    mfccs = lf.mfcc(y=y, sr=sr, n_mfcc=40)
    mfccs = np.mean(mfccs.T, axis=0)
    # Chroma
    stft = np.abs(librosa.stft(y))
    chroma = lf.chroma_stft(S=stft, sr=sr)
    chroma = np.mean(chroma.T, axis=0)
    # Mel
    mel = lf.melspectrogram(y=y, sr=sr)
    mel = np.mean(mel.T, axis=0)
    # Contrast
    contrast = lf.spectral_contrast(S=stft, sr=sr)
    contrast = np.mean(contrast.T, axis=0)
    # Tonnetz
    tonnetz = lf.tonnetz(y=librosa.effects.harmonic(y), sr=sr)
    tonnetz = np.mean(tonnetz.T, axis=0)
    # Stack features
    return np.hstack([mfccs, chroma, mel, contrast, tonnetz])

# Extract for all
features = []
for path in df['speech']:
    features.append(extract_features(path))
X = np.array(features)

# Encode labels
y = LabelEncoder().fit_transform(df['label'])

print(f"Feature matrix shape: {X.shape}")

# 5. Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(f"Train shape: {X_train.shape}, Test shape: {X_test.shape}")

# 6. Model Training
# 6.1 MLP
mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300)
mlp.fit(X_train, y_train)
print(f"MLP Accuracy: {mlp.score(X_test, y_test):.2f}")

# 6.2 Random Forest
rf = RandomForestClassifier(n_estimators=100)
rf.fit(X_train, y_train)
print(f"Random Forest Accuracy: {rf.score(X_test, y_test):.2f}")

# 6.3 SVM
svc = SVC(kernel='linear')
svc.fit(X_train, y_train)
print(f"SVM Accuracy: {svc.score(X_test, y_test):.2f}")

# 7. Evaluation
# Classification Report for RF
y_pred = rf.predict(X_test)
print(classification_report(y_test, y_pred, target_names=LabelEncoder().fit(df['label']).classes_))

# Confusion Matrix
def plot_confusion(y_true, y_pred, labels):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8,6))
    sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels)
    plt.ylabel('True')
    plt.xlabel('Predicted')
    plt.title('Confusion Matrix')
    plt.show()

plot_confusion(y_test, y_pred, LabelEncoder().fit(df['label']).classes_)

# Save model
joblib.dump(rf, 'random_forest_emotion_model.pkl')

# 8. Chat Prototype Functions
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression

# Dummy NLP model for text fallback
vectorizer = TfidfVectorizer()
clf_text = LogisticRegression()

# Example fit (replace with real corpus)
texts = ["hello", "how are you"]
labels_text = [0, 1]
X_text = vectorizer.fit_transform(texts)
clf_text.fit(X_text, labels_text)


def get_chatbot_reply_final(user_text, current_voice_emotion, fallback_face_emotion="N/A"):
    # Simple rule-based reply example
    if current_voice_emotion == 'happy':
        return "You sound happy today! How can I help?"
    # Fallback to text classifier
    vec = vectorizer.transform([user_text])
    pred = clf_text.predict(vec)[0]
    return "Tell me more." if pred == 0 else "Interesting!"

# 9. Chat Interface

def show_chat_mode_selection(username):
    chat_mode = widgets.Dropdown(
        options=["Text Chat", "Voice Chat", "Video Chat"],
        description="Chat Mode:"
    )
    start_chat_button = widgets.Button(description="Start Chat")
    display(chat_mode, start_chat_button)


# 10. Run Prototype

def run_prototype():
    print("Welcome to the Voice-Text Chat Prototype! Please log in.")
    login_username = widgets.Text(description="Username:")
    login_password = widgets.Password(description="Password:")
    login_button   = widgets.Button(description="Login")
    display(login_username, login_password, login_button)

    def on_login_clicked(b):
        user = login_username.value
        print(f"Login successful. Hello, {user}!")
        show_chat_mode_selection(user)
    login_button.on_click(on_login_clicked)

# Launch
if __name__ == "__main__":
    run_prototype()
